{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/spanish_words2phones.csv'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set path to data and language variable in lowercase (e.g. spanish) and run the rest\n",
    "path = '../../datasets/'\n",
    "language = 'spanish'\n",
    "file_name = path+language+'_words2phones.csv'\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ipa</th>\n",
       "      <th>ARPAbet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaleniana</td>\n",
       "      <td>a l e n j a n a</td>\n",
       "      <td>AE L EH N Y AE N AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aalenianas</td>\n",
       "      <td>a l e n j a n a s</td>\n",
       "      <td>AE L EH N Y AE N AE S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaleniano</td>\n",
       "      <td>a l e n j a n o</td>\n",
       "      <td>AE L EH N Y AE N OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalenianos</td>\n",
       "      <td>a l e n j a n a s</td>\n",
       "      <td>AE L EH N Y AE N AE S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ababa</td>\n",
       "      <td>a b a b a</td>\n",
       "      <td>AE B AE B AE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                ipa                ARPAbet\n",
       "0   aaleniana    a l e n j a n a    AE L EH N Y AE N AE\n",
       "1  aalenianas  a l e n j a n a s  AE L EH N Y AE N AE S\n",
       "2   aaleniano    a l e n j a n o    AE L EH N Y AE N OH\n",
       "3  aalenianos  a l e n j a n a s  AE L EH N Y AE N AE S\n",
       "4       ababa          a b a b a           AE B AE B AE"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in csv file\n",
    "data_table = pd.read_csv(file_name)\n",
    "data_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and convert to list\n",
    "data_arr = np.array((data_table['word']+' '+data_table['ARPAbet'])).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['aaleniana AE L EH N Y AE N AE'],\n",
       "       ['aalenianas AE L EH N Y AE N AE S'],\n",
       "       ['aaleniano AE L EH N Y AE N OH'],\n",
       "       ...,\n",
       "       ['útero UW T EH DX OH'],\n",
       "       ['útica UW T IH K AE'],\n",
       "       ['ü W']], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aaleniana', 'AE', 'L', 'EH', 'N', 'Y', 'AE', 'N', 'AE'],\n",
       " ['aalenianas', 'AE', 'L', 'EH', 'N', 'Y', 'AE', 'N', 'AE', 'S'],\n",
       " ['aaleniano', 'AE', 'L', 'EH', 'N', 'Y', 'AE', 'N', 'OH'],\n",
       " ['aalenianos', 'AE', 'L', 'EH', 'N', 'Y', 'AE', 'N', 'AE', 'S'],\n",
       " ['ababa', 'AE', 'B', 'AE', 'B', 'AE']]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing seperated values in a list since it's easier to work with strings\n",
    "data_list = []\n",
    "non_strings = []\n",
    "for item in data_arr:\n",
    "    if type(item[0]) == str:\n",
    "        data_list.append(item[0].split(' '))\n",
    "    else:\n",
    "        non_strings.append(item[0])\n",
    "data_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what kind of info was excluded\n",
    "non_strings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aaleniana', 'start', 'AE', 'L', 'EH', 'N', 'Y', 'AE', 'N', 'AE', 'stop'],\n",
       " ['aalenianas',\n",
       "  'start',\n",
       "  'AE',\n",
       "  'L',\n",
       "  'EH',\n",
       "  'N',\n",
       "  'Y',\n",
       "  'AE',\n",
       "  'N',\n",
       "  'AE',\n",
       "  'S',\n",
       "  'stop'],\n",
       " ['aaleniano', 'start', 'AE', 'L', 'EH', 'N', 'Y', 'AE', 'N', 'OH', 'stop'],\n",
       " ['aalenianos',\n",
       "  'start',\n",
       "  'AE',\n",
       "  'L',\n",
       "  'EH',\n",
       "  'N',\n",
       "  'Y',\n",
       "  'AE',\n",
       "  'N',\n",
       "  'AE',\n",
       "  'S',\n",
       "  'stop'],\n",
       " ['ababa', 'start', 'AE', 'B', 'AE', 'B', 'AE', 'stop']]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a stop character to the end of each word\n",
    "for item in data_list:\n",
    "    item.append('stop')\n",
    "for item in data_list:\n",
    "    item.insert(1, 'start')\n",
    "data_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aaleniana', 'start'],\n",
       " ['aaleniana', 'start', 'AE'],\n",
       " ['aaleniana', 'start', 'AE', 'L'],\n",
       " ['aaleniana', 'start', 'AE', 'L', 'EH'],\n",
       " ['aaleniana', 'start', 'AE', 'L', 'EH', 'N'],\n",
       " ['aaleniana', 'start', 'AE', 'L', 'EH', 'N', 'Y'],\n",
       " ['aaleniana', 'start', 'AE', 'L', 'EH', 'N', 'Y', 'AE']]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extending the data so each word incrementally gains one of its phonemes\n",
    "extended_data = []\n",
    "for item in data_list:\n",
    "        for i in range(len(item)-1):\n",
    "            extended_data.append(item[:i+2])\n",
    "extended_data[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to dict file\n",
    "out_file = path + 'processed/processed_' + language + '.dict'\n",
    "with open(out_file, \"w\") as txt_file:\n",
    "    for line in extended_data:\n",
    "        txt_file.write(\" \".join(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aaleniana', '', 'start'],\n",
       " ['aaleniana', 'start', 'AE'],\n",
       " ['aaleniana', 'start AE', 'L'],\n",
       " ['aaleniana', 'start AE L', 'EH'],\n",
       " ['aaleniana', 'start AE L EH', 'N']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process = []\n",
    "for item in extended_data:\n",
    "    pre_process.append([item[0], ' '.join(item[1:-1]), item[-1]])\n",
    "pre_process[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pre_process, columns = ['word', 'phonemes', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = path + 'processed/processed_' + language + '.csv'\n",
    "df.to_csv(out_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
